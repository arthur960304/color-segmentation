{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ECE276A WI20 HW1\n",
    "Stop Sign Detector\n",
    "'''\n",
    "\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label, regionprops\n",
    "from gaussian_model import SimpleGaussian\n",
    "#from logistic_model import LogisticRegression\n",
    "\n",
    "class StopSignDetector():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "            Initilize your stop sign detector with the attributes you need,\n",
    "            e.g., parameters of your classifier\n",
    "        '''\n",
    "        # choose which method to try\n",
    "        # \"SimpleGaussian\", \"NaiveBayes\", or \"LogisticRegression\"\n",
    "        self.method = \"NaiveBayes\"\n",
    "\n",
    "        # initialize mean value for each class\n",
    "        self.mean_dict = {}\n",
    "        self.mean_dict['COLOR_RED']\t\t= np.array([122.90029146,  36.63952687,  42.20470774])\n",
    "        self.mean_dict['COLOR_BROWN']\t= np.array([133.48214699, 100.11578226,  71.49936706])\n",
    "        self.mean_dict['COLOR_OTHER']\t= np.array([110.91446659, 120.69703685, 126.29357601])\n",
    "\n",
    "        # initialize covariance matrix for each class\n",
    "        self.cov_dict = {}\n",
    "        self.cov_dict['COLOR_RED']  \t= np.array([[3472.85255899, -189.07265668,   63.89804755],\n",
    "                                                    [-189.07265668, 1106.75494927,  978.63599331],\n",
    "                                                    [63.89804755,  978.63599331,  990.83383879]])\n",
    "        self.cov_dict['COLOR_BROWN']\t= np.array([[3875.35170522, 2855.30289674, 1720.8232254 ],\n",
    "                                                    [2855.30289674, 2473.60440071, 1839.71033185],\n",
    "                                                    [1720.8232254 , 1839.71033185, 1859.3362903 ]])\n",
    "        self.cov_dict['COLOR_OTHER']\t= np.array([[3287.09643207, 3056.21297624, 2879.15061134],\n",
    "                                                    [3056.21297624, 3286.23666639, 3530.60415906],\n",
    "                                                    [2879.15061134, 3530.60415906, 4653.45892218]])\n",
    "\n",
    "        # initialize prior for each class\n",
    "        self.prior_dict = {}\n",
    "        self.prior_dict['COLOR_RED']\t= 0.016864184071881394\n",
    "        self.prior_dict['COLOR_BROWN']\t= 0.04490358080450406\n",
    "        self.prior_dict['COLOR_OTHER']\t= 0.9371541010520053\n",
    "\n",
    "    # determine if two boxes are supposed to be one\n",
    "    def is_cross(self, rect1, rect2):\n",
    "        left_diff = abs(rect1[0] - rect2[0])\n",
    "        mid_diff  = min(abs(rect1[3] - rect2[1]), abs(rect1[1] - rect2[3]))\n",
    "        right_diff = abs(rect1[2] - rect2[2])\n",
    "        #righty = min(rect1[3], rect2[3])\n",
    "        #print(left_diff, right_diff, mid_diff)\n",
    "        if left_diff > 10 or right_diff > 10 or mid_diff > 20:\n",
    "            return False\n",
    "        else:\n",
    "            x1 = min(rect1[0], rect2[0])\n",
    "            y1 = min(rect1[1], rect2[1])\n",
    "            x2 = max(rect1[2], rect2[2])\n",
    "            y2 = max(rect1[3], rect2[3])\n",
    "            new_rect = [x1, y1, x2, y2]\n",
    "            return new_rect\n",
    "\n",
    "    # merge boxes\n",
    "    def merge_rect(self, boxes):\n",
    "        if len(boxes) == 1:\n",
    "            return\n",
    "        for i in range(len(boxes) - 1):\n",
    "            for j in range(i + 1, len(boxes)):\n",
    "                if j >= len(boxes):\n",
    "                    return\n",
    "                if self.is_cross(boxes[i], boxes[j]):\n",
    "                    boxes.append(self.is_cross(boxes[i], boxes[j]))\n",
    "                    boxes.remove(boxes[i])\n",
    "                    boxes.remove(boxes[j - 1])\n",
    "                    self.merge_rect(boxes)\n",
    "        return\n",
    "\n",
    "    def compute_score(self, w, h, area_ratio, euler_num, img_size):\n",
    "        score = 0\n",
    "        if(w < img_size[1]/12 or h < img_size[0]/12):\n",
    "            score -= 5\n",
    "        if(w >= img_size[1]/10 and h >= img_size[0]/10):\n",
    "            score += 1\n",
    "        if(w/h < 1.4 and w/h > 0.7):\n",
    "            score += 2\n",
    "        else:\n",
    "            score -= 2\n",
    "        if(area_ratio >= 0.5 and area_ratio <= 0.8):\n",
    "            score += 5\n",
    "        else:\n",
    "            score -= 5\n",
    "        if(euler_num < 0 and euler_num >= -9 or euler_num <= -15):\n",
    "            score += 5\n",
    "        elif(euler_num > -15 and euler_num < -9 or euler_num > 0):\n",
    "            score -= 5\n",
    "        return score\n",
    "\n",
    "    def segment_image(self, img):\n",
    "        '''\n",
    "            Obtain a segmented image using a color classifier,\n",
    "            e.g., Logistic Regression, Single Gaussian Generative Model, Gaussian Mixture, \n",
    "            call other functions in this class if needed\n",
    "\n",
    "            Inputs:\n",
    "                img - original image\n",
    "            Outputs:\n",
    "                mask_img - a binary image with 1 if the pixel in the original image is red and 0 otherwise\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        # create simple gaussian model for different classes\n",
    "\n",
    "        model_red \t\t= SimpleGaussian(self.mean_dict['COLOR_RED'], self.cov_dict['COLOR_RED'])\n",
    "        model_brown \t= SimpleGaussian(self.mean_dict['COLOR_BROWN'], self.cov_dict['COLOR_BROWN'])\n",
    "        model_other \t= SimpleGaussian(self.mean_dict['COLOR_OTHER'], self.cov_dict['COLOR_OTHER'])\n",
    "\n",
    "        # convert BGR to RGB\n",
    "        # and reshape to (N,3)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_size = np.shape(img)\n",
    "        img = np.reshape(img, (-1,3))\n",
    "\n",
    "        # predict\n",
    "        if(self.method == \"SimpleGaussian\"):\n",
    "            pixel_red \t\t= model_red.predict(img)\n",
    "            pixel_brown     = model_brown.predict(img)\n",
    "            pixel_other     = model_other.predict(img)\n",
    "        elif(self.method == \"NaiveBayes\"):\n",
    "            pixel_red \t\t= model_red.predict(img) * self.prior_dict['COLOR_RED']\n",
    "            pixel_brown     = model_brown.predict(img) * self.prior_dict['COLOR_BROWN']\n",
    "            pixel_other     = model_other.predict(img) * self.prior_dict['COLOR_OTHER']\n",
    "\n",
    "        # find max probability for each pixel\n",
    "        tmp1 = pixel_red.tolist()\n",
    "        tmp2 = pixel_brown.tolist()\n",
    "        tmp3 = pixel_other.tolist()\n",
    "        max_tmp = list(map(max, zip(tmp1, tmp2, tmp3)))\n",
    "        max_tmp = np.array(max_tmp)\n",
    "\n",
    "        # create mask image\n",
    "        mask_img = 255*np.array(max_tmp == pixel_red).astype('uint8')\n",
    "        mask_img = cv2.dilate(mask_img, (25,25), iterations = 10)\n",
    "        mask_img = cv2.erode(mask_img, (25,25), iterations = 10)\n",
    "        mask_img = mask_img.reshape(img_size[:2])\n",
    "\n",
    "        return mask_img\n",
    "\n",
    "\n",
    "    def get_bounding_box(self, img):\n",
    "        '''\n",
    "            Find the bounding box of the stop sign\n",
    "            call other functions in this class if needed\n",
    "\n",
    "            Inputs:\n",
    "                img - original image\n",
    "            Outputs:\n",
    "                boxes - a list of lists of bounding boxes. Each nested list is a bounding box in the form of [x1, y1, x2, y2] \n",
    "                where (x1, y1) and (x2, y2) are the top left and bottom right coordinate respectively. The order of bounding boxes in the list\n",
    "                is from left to right in the image.\n",
    "\n",
    "            Our solution uses xy-coordinate instead of rc-coordinate. More information: http://scikit-image.org/docs/dev/user_guide/numpy_images.html#coordinate-conventions\n",
    "        '''\n",
    "        # get the masked image\n",
    "        mask_img = self.segment_image(img)\n",
    "        img_size = np.shape(mask_img)\n",
    "        boxes = []\n",
    "        label_img = label(mask_img)\n",
    "        regions = regionprops(label_img)\n",
    "        potential_boxes = []\n",
    "        \n",
    "        for props in regions:\n",
    "            box = props.bbox\n",
    "            x, y, w, h = box[1], box[0], box[3]-box[1], box[2]-box[0]\n",
    "            radius = w / 2\n",
    "            area_ratio = props.extent\n",
    "            euler_num  = props.euler_number\n",
    "            area = props.area\n",
    "            circle_area = radius**2*3.14\n",
    "            convex_region = props.convex_image\n",
    "            plt.imshow(convex_region)\n",
    "            \n",
    "            score = self.compute_score(w, h, area_ratio, euler_num, img_size)\n",
    "            #print(score, x,y,w,h, area_ratio, euler_num, img_size)\n",
    "            #cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 3)\n",
    "            if(score > 3):\n",
    "                print(score, x, y, w, h, area_ratio, euler_num)\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 3)\n",
    "                boxes.append([x,img_size[0]-y-h,x+w,img_size[0]-y])\n",
    "            \n",
    "        \n",
    "        # get contours\n",
    "        _, contours, _ = cv2.findContours(mask_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            area = cv2.contourArea(contour)\n",
    "            \n",
    "            # shortlisting the regions based on the area\n",
    "            #print(area, (img_size[1]/25) * (img_size[0]/25))\n",
    "            \n",
    "            if(area > (img_size[1]/25) * (img_size[0]/25)):\n",
    "                approx = cv2.approxPolyDP(contour, 0.01 * cv2.arcLength(contour, True), True)\n",
    "                print(len(approx))\n",
    "                if(len(approx)%4==0):\n",
    "                    if w/h > 1.4 or w/h < 0.5 or w < img_size[1]/30 or h < img_size[0]/30:\n",
    "                        continue\n",
    "                    else:\n",
    "                        cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 3)\n",
    "                        box = [x,img_size[0]-y-h,x+w,img_size[0]-y]\n",
    "                        if(box not in boxes):\n",
    "                            boxes.append(box)\n",
    "\n",
    "\n",
    "#                     cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 3)\n",
    "#                     box = [x,img_size[0]-y-h,x+w,img_size[0]-y]\n",
    "#                     if(box not in boxes):\n",
    "#                         boxes.append(box)\n",
    "\n",
    "        # merge the crossed box\n",
    "#         self.merge_rect(boxes)\n",
    "\n",
    "#         new_boxes = []\n",
    "#         for box in boxes:\n",
    "#             x, y, w, h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
    "#             # checked the ratio of merged boxes\n",
    "#             if w/h > 1.4 or w/h < 0.5 or w < 30 or h < 30:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 cv2.rectangle(img, (x, y), (x+w, y+h), (0,255,0), 3)\n",
    "#                 new_boxes.append([x,img_size[0]-y-h,x+w,img_size[0]-y])\n",
    "#         boxes = new_boxes\n",
    "\n",
    "        # the order of bounding boxes in the list is from left to right in the image\n",
    "        if(len(boxes) > 1):\n",
    "            boxes.sort(key = lambda x: x[0])\n",
    "        print(\"Number of bbox:\", len(boxes))\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    folder = \"trainset\"\n",
    "    my_detector = StopSignDetector()\n",
    "\n",
    "    img = cv2.imread('trainset/63.png')\n",
    "\n",
    "    #Display results:\n",
    "    #(1) Segmented images\n",
    "    mask_img = my_detector.segment_image(img)\n",
    "\n",
    "    #(2) Stop sign bounding box\n",
    "    boxes = my_detector.get_bounding_box(img)\n",
    "    \n",
    "    # show image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(121)\n",
    "    plt.gca().set_title('Masked Image')\n",
    "    plt.imshow(mask_img)\n",
    "    #plt.savefig('mask.jpg', dpi=100, bbox_inches='tight')\n",
    "    plt.subplot(122)\n",
    "    plt.gca().set_title('Bounding Box')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
